# âœï¸ Comparative Analysis of Text Representations for Author Identification and Style Modeling

This project compares five different text representation methods for **authorship attribution** and **style modeling** on a curated dataset of literary prose.  
We evaluate both **in-domain performance** and **generalization to unseen works** by the same authors, with analysis across excerpt lengths and authors.

---

## ğŸ“‘ Overview

We experiment with the following representations:
- **TFâ€“IDF** â€” sparse lexical features
- **Stylometric features** â€” handcrafted style metrics (sentence length, punctuation use, function word frequencies, etc.)
- **Word2Vec embeddings** â€” static semantic vectors, aggregated at document level
- **BiLSTM encodings** â€” sequence-based learned embeddings
- **SBERT embeddings** â€” contextual transformer-based embeddings (fine-tuned)

Each representation is paired with appropriate classifiers (e.g., Logistic Regression, SVM, MLP), and evaluated for:
- In-domain classification accuracy and macro-F1
- Out-of-domain Top-1 and Top-2 accuracy
- Performance differences on short vs. long excerpts
- Per-author variation in generalization

---

## ğŸ“‚ Dataset

Five canonicalauthors:
- Charlotte BrontÃ«
- Edith Wharton
- George Eliot
- Henry James
- Virginia Woolf

**Source**: Public-domain works from [Project Gutenberg](https://www.gutenberg.org/).

**Splits**:
- **Train/Test**: Balanced excerpts of ~300â€“500 words
- **Unseen Evaluation Set**:
  - Short excerpts: 50â€“100 words
  - Long excerpts: 150â€“300 words

---

## ğŸš€ Running the Project

### 1ï¸âƒ£ Install dependencies
```bash
pip install torch sentence-transformers scikit-learn gensim nltk tqdm matplotlib numpy pandas
```

### 2ï¸âƒ£ Prepare the data
Either use the prepared CSV/JSON datasets in data/,
or regenerate excerpts and feature sets with the preprocessing scripts.

### 3ï¸âƒ£ Train the model
```bash
# TFâ€“IDF + Logistic Regression
python -m scripts.train_tfidf

# Stylometry + Logistic Regression
python -m scripts.train_stylometry

# Word2Vec + Classifier
python -m scripts.train_word2vec

# BiLSTM Encoder
python -m scripts.train_lstm

# SBERT Fine-tuning
python -m scripts.train_sbert

```

### 4ï¸âƒ£ Evaluate the model
```bash
python -m scripts.evaluate_model --models "tfidf stylometry word2vec lstm sbert"
```


---

## ğŸ“‚ Project Structure
## ğŸ“¦ authorship_attribution
 â”œâ”€â”€ ğŸ“ data/               # ğŸ“„ Input datasets and references
 â”œâ”€â”€ ğŸ“ models/             # ğŸ’¾ Different Models
 â”œâ”€â”€ ğŸ“ results/            # ğŸ“Š Evaluation Outputs
 â”œâ”€â”€ ğŸ“ scripts/            # ğŸ› ï¸ Training, inference, and evaluation scripts
 â””â”€â”€ README.md              # ğŸ“œ Project documentation


